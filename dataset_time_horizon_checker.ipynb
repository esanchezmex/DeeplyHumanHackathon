{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset Time Horizon Checker\n",
        "\n",
        "This notebook analyzes all datasets across the 6 category folders to identify their time coverage (min/max years). This helps identify which datasets have limited time horizons and may need updating.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_dataset_time_range(filepath):\n",
        "    \"\"\"\n",
        "    Check the time range (min/max years) of a dataset file.\n",
        "    \n",
        "    Args:\n",
        "        filepath: Path to the CSV file\n",
        "    \n",
        "    Returns:\n",
        "        dict with min_year, max_year, data_points, and status\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        \n",
        "        if 'time' not in df.columns:\n",
        "            return {\n",
        "                'min_year': None,\n",
        "                'max_year': None,\n",
        "                'data_points': 0,\n",
        "                'status': 'Error: No time column'\n",
        "            }\n",
        "        \n",
        "        if len(df) == 0:\n",
        "            return {\n",
        "                'min_year': None,\n",
        "                'max_year': None,\n",
        "                'data_points': 0,\n",
        "                'status': 'Error: Empty file'\n",
        "            }\n",
        "        \n",
        "        min_year = int(df['time'].min())\n",
        "        max_year = int(df['time'].max())\n",
        "        data_points = len(df)\n",
        "        \n",
        "        # Determine status based on max year\n",
        "        current_year = 2025\n",
        "        years_behind = current_year - max_year\n",
        "        \n",
        "        if max_year >= 2024:\n",
        "            status = 'Up to date'\n",
        "        elif max_year >= 2020:\n",
        "            status = f'{years_behind} years behind'\n",
        "        elif max_year >= 2015:\n",
        "            status = f'{years_behind} years behind (Limited)'\n",
        "        else:\n",
        "            status = f'{years_behind} years behind (Very Limited)'\n",
        "        \n",
        "        return {\n",
        "            'min_year': min_year,\n",
        "            'max_year': max_year,\n",
        "            'data_points': data_points,\n",
        "            'status': status\n",
        "        }\n",
        "    \n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'min_year': None,\n",
        "            'max_year': None,\n",
        "            'data_points': 0,\n",
        "            'status': f'Error: {str(e)}'\n",
        "        }\n",
        "\n",
        "\n",
        "def extract_indicator_name(filename):\n",
        "    \"\"\"\n",
        "    Extract indicator name from filename.\n",
        "    Pattern: ddf--datapoints--{indicator}--by--geo--time.csv\n",
        "    \"\"\"\n",
        "    if 'ddf--datapoints--' in filename and '--by--geo--time.csv' in filename:\n",
        "        indicator = filename.replace('ddf--datapoints--', '').replace('--by--geo--time.csv', '')\n",
        "        return indicator\n",
        "    return filename.replace('.csv', '')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main Analysis Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_all_datasets(base_dir='./data/gapminder'):\n",
        "    \"\"\"\n",
        "    Analyze all datasets in category folders and return a summary DataFrame.\n",
        "    \n",
        "    Args:\n",
        "        base_dir: Base directory containing category folders\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with time horizon information for all datasets\n",
        "    \"\"\"\n",
        "    base_path = Path(base_dir)\n",
        "    categories = [\"Physical\", \"Mental\", \"Social\", \"Economic\", \"Environmental\", \"Cultural\"]\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for category in categories:\n",
        "        category_path = base_path / category\n",
        "        \n",
        "        if not category_path.exists():\n",
        "            print(f\"Warning: Category folder '{category}' not found\")\n",
        "            continue\n",
        "        \n",
        "        # Find all CSV files in the category folder\n",
        "        csv_files = list(category_path.glob('ddf--datapoints--*.csv'))\n",
        "        \n",
        "        if len(csv_files) == 0:\n",
        "            print(f\"Warning: No datasets found in '{category}' folder\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"Analyzing {len(csv_files)} datasets in '{category}'...\")\n",
        "        \n",
        "        for filepath in csv_files:\n",
        "            indicator = extract_indicator_name(filepath.name)\n",
        "            time_info = check_dataset_time_range(filepath)\n",
        "            \n",
        "            results.append({\n",
        "                'Category': category,\n",
        "                'Dataset': indicator,\n",
        "                'Min Year': time_info['min_year'],\n",
        "                'Max Year': time_info['max_year'],\n",
        "                'Year Range': f\"{time_info['min_year']}-{time_info['max_year']}\" if time_info['min_year'] and time_info['max_year'] else 'N/A',\n",
        "                'Data Points': time_info['data_points'],\n",
        "                'Status': time_info['status']\n",
        "            })\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Run the analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"Analyzing Time Horizons for All Datasets\")\n",
        "print(\"=\" * 70)\n",
        "print()\n",
        "\n",
        "results_df = analyze_all_datasets()\n",
        "\n",
        "print(f\"\\n✅ Analysis complete! Found {len(results_df)} datasets across {results_df['Category'].nunique()} categories.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display results grouped by category\n",
        "categories = [\"Physical\", \"Mental\", \"Social\", \"Economic\", \"Environmental\", \"Cultural\"]\n",
        "\n",
        "for category in categories:\n",
        "    category_data = results_df[results_df['Category'] == category]\n",
        "    \n",
        "    if len(category_data) == 0:\n",
        "        continue\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"{category.upper()} ({len(category_data)} datasets)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Display table\n",
        "    display_cols = ['Dataset', 'Min Year', 'Max Year', 'Year Range', 'Data Points', 'Status']\n",
        "    print(category_data[display_cols].to_string(index=False))\n",
        "    \n",
        "    # Summary for this category\n",
        "    if category_data['Max Year'].notna().any():\n",
        "        avg_max_year = category_data['Max Year'].mean()\n",
        "        min_max_year = category_data['Max Year'].min()\n",
        "        max_max_year = category_data['Max Year'].max()\n",
        "        print(f\"\\n  Summary: Average max year = {avg_max_year:.0f}, Range = {min_max_year:.0f}-{max_max_year:.0f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overall Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overall statistics\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"OVERALL STATISTICS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Count datasets by max year\n",
        "print(\"Datasets by Maximum Year:\")\n",
        "max_year_counts = results_df['Max Year'].value_counts().sort_index(ascending=False)\n",
        "for year, count in max_year_counts.head(10).items():\n",
        "    if pd.notna(year):\n",
        "        print(f\"  {int(year)}: {count} dataset(s)\")\n",
        "\n",
        "# Count by status\n",
        "print(f\"\\nDatasets by Status:\")\n",
        "status_counts = results_df['Status'].value_counts()\n",
        "for status, count in status_counts.items():\n",
        "    print(f\"  {status}: {count} dataset(s)\")\n",
        "\n",
        "# Summary statistics\n",
        "print(f\"\\nSummary Statistics:\")\n",
        "print(f\"  Total datasets analyzed: {len(results_df)}\")\n",
        "print(f\"  Total categories: {results_df['Category'].nunique()}\")\n",
        "\n",
        "if results_df['Max Year'].notna().any():\n",
        "    print(f\"  Earliest max year: {int(results_df['Max Year'].min())}\")\n",
        "    print(f\"  Latest max year: {int(results_df['Max Year'].max())}\")\n",
        "    print(f\"  Average max year: {results_df['Max Year'].mean():.1f}\")\n",
        "    print(f\"  Median max year: {results_df['Max Year'].median():.0f}\")\n",
        "\n",
        "# Count datasets that need updating (max year < 2024)\n",
        "needs_update = results_df[results_df['Max Year'] < 2024]\n",
        "print(f\"\\n  Datasets needing updates (max year < 2024): {len(needs_update)}\")\n",
        "\n",
        "# Count datasets up to date (max year >= 2024)\n",
        "up_to_date = results_df[results_df['Max Year'] >= 2024]\n",
        "print(f\"  Datasets up to date (max year >= 2024): {len(up_to_date)}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datasets Needing Updates\n",
        "\n",
        "Datasets with max year < 2024 that may need updating:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show datasets that need updating\n",
        "needs_update = results_df[results_df['Max Year'] < 2024].copy()\n",
        "\n",
        "if len(needs_update) > 0:\n",
        "    # Sort by max year (oldest first)\n",
        "    needs_update = needs_update.sort_values('Max Year')\n",
        "    \n",
        "    print(f\"\\nFound {len(needs_update)} datasets with max year < 2024:\\n\")\n",
        "    display_cols = ['Category', 'Dataset', 'Max Year', 'Status']\n",
        "    print(needs_update[display_cols].to_string(index=False))\n",
        "    \n",
        "    # Group by max year\n",
        "    print(f\"\\n\\nGrouped by Max Year:\")\n",
        "    for max_year in sorted(needs_update['Max Year'].unique(), reverse=True):\n",
        "        datasets = needs_update[needs_update['Max Year'] == max_year]\n",
        "        print(f\"\\n  Max Year = {int(max_year)} ({len(datasets)} dataset(s)):\")\n",
        "        for _, row in datasets.iterrows():\n",
        "            print(f\"    - {row['Category']}/{row['Dataset']}\")\n",
        "else:\n",
        "    print(\"\\n✅ All datasets are up to date (max year >= 2024)!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization: Maximum Year by Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create visualization\n",
        "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
        "\n",
        "# Plot 1: Bar chart of max year by dataset\n",
        "ax1 = axes[0]\n",
        "results_sorted = results_df.sort_values('Max Year', na_position='last')\n",
        "colors = ['green' if y >= 2024 else 'orange' if y >= 2020 else 'red' if pd.notna(y) else 'gray' \n",
        "          for y in results_sorted['Max Year']]\n",
        "\n",
        "bars = ax1.barh(range(len(results_sorted)), results_sorted['Max Year'], color=colors, alpha=0.7)\n",
        "ax1.set_yticks(range(len(results_sorted)))\n",
        "ax1.set_yticklabels([f\"{row['Category']}/{row['Dataset']}\" for _, row in results_sorted.iterrows()], fontsize=9)\n",
        "ax1.set_xlabel('Maximum Year', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Maximum Year by Dataset\\n(Green: ≥2024, Orange: 2020-2023, Red: <2020)', \n",
        "              fontsize=13, fontweight='bold', pad=15)\n",
        "ax1.axvline(x=2024, color='blue', linestyle='--', alpha=0.5, label='Target (2024)')\n",
        "ax1.axvline(x=2025, color='purple', linestyle='--', alpha=0.5, label='Goal (2025)')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Plot 2: Distribution of max years\n",
        "ax2 = axes[1]\n",
        "valid_years = results_df['Max Year'].dropna()\n",
        "if len(valid_years) > 0:\n",
        "    ax2.hist(valid_years, bins=range(int(valid_years.min()), int(valid_years.max())+2), \n",
        "             edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    ax2.axvline(x=2024, color='red', linestyle='--', linewidth=2, label='Target (2024)')\n",
        "    ax2.axvline(x=2025, color='purple', linestyle='--', linewidth=2, label='Goal (2025)')\n",
        "    ax2.set_xlabel('Maximum Year', fontsize=12, fontweight='bold')\n",
        "    ax2.set_ylabel('Number of Datasets', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title('Distribution of Maximum Years Across All Datasets', \n",
        "                  fontsize=13, fontweight='bold', pad=15)\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(f\"\\nColor Legend:\")\n",
        "print(f\"  Green: Up to date (max year ≥ 2024)\")\n",
        "print(f\"  Orange: Recent but needs update (max year 2020-2023)\")\n",
        "print(f\"  Red: Limited coverage (max year < 2020)\")\n",
        "print(f\"  Gray: Error or missing data\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
